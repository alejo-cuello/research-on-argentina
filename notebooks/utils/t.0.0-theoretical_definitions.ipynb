{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of missing data:\n",
    "\n",
    "**MCAR: Missing Completely At Random**  \n",
    "The missing values in the data set occur completely at random. They don't depend on any other data. Example: when a device such a security camera stops working.  \n",
    "*How to handle this kind of missing data? Apply data deletion or imputation (imputation is more recommended)*  \n",
    "\n",
    "**MAR: Missing At Random**  \n",
    "    The missing values depends on other observed values. Example: devices required a periodic maintenance to ensure consistent operation, so the data will be missing during those maintenance period.  \n",
    "    *How to handle this kind of missing data? Single or multiple imputation (consider one or several columns during imputation)*  \n",
    "\n",
    "**MNAR: Missing Not At Random**  \n",
    "    The missing values depends on the missing values themselves. They are very difficult to identify. And we may not even know that the data is missing. Example: tools have limitations. When attempting to track data out in areas beyond the measurement range, missing values are generated. Example, a scale not detecting very small or very large values.  \n",
    "    *How to handle this kind of missing data? This kind of missing values require to perform sensivity analysis. If it's not possible, imputation is preferable over deletion.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTest functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scipy.stats.ttest_* functions (like ttest_ind, ttest_rel, and ttest_1samp) perform a t-test, which is a statistical hypothesis test to compare means. These functions typically return two values:\n",
    "\n",
    "* Statistic: The t-statistic is a measure of how far the sample mean is from the null hypothesis (e.g., the means are equal) in terms of standard error. A higher absolute value indicates a stronger deviation from the null hypothesis.\n",
    "* p-value: This value represents the probability of observing the data (or something more extreme) under the null hypothesis. If the p-value is below your chosen significance level (e.g., 0.05), you can reject the null hypothesis.\n",
    "\n",
    "**Example Explanation**\n",
    "\n",
    "Suppose you run:\n",
    "```python\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Example data\n",
    "sample1 = [2.3, 3.5, 4.2, 5.6, 6.8]\n",
    "sample2 = [1.2, 2.8, 3.4, 4.7, 5.9]\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_val = ttest_ind(sample1, sample2)\n",
    "\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)\n",
    "```\n",
    "\n",
    "**\"alternative\" Function Parameter**\n",
    "\n",
    "Defines the alternative hypothesis. The following options are available (default is ‘two-sided’):\n",
    "- two-sided: the means of the distributions underlying the samples are unequal.\n",
    "- less: the mean of the distribution underlying the first sample is less than the mean of the distribution underlying the second sample.\n",
    "- greater: the mean of the distribution underlying the first sample is greater than the mean of the distribution underlying the second sample.\n",
    "\n",
    "**Output Interpretation**\n",
    "\n",
    "- t-statistic:\n",
    "    - A positive or negative value indicating the difference between the means.\n",
    "    - A positive value means the mean of sample1 is higher than sample2.\n",
    "    - A negative value means the mean of sample1 is lower than sample2.\n",
    "    - Larger absolute values indicate greater evidence against the null hypothesis.\n",
    "\n",
    "- p-value:\n",
    "    - A small p-value (e.g., < 0.05) suggests a significant difference between the two groups.\n",
    "    - A large p-value means the evidence is insufficient to reject the null hypothesis.\n",
    "\n",
    "**Common Use Cases**\n",
    "\n",
    "- ttest_ind:\n",
    "    - Used for two independent samples.\n",
    "    - Example: Comparing test scores between two different classes.\n",
    "\n",
    "- ttest_rel:\n",
    "    - Used for two related samples (paired samples).\n",
    "    - Example: Comparing the same students' test scores before and after a course.\n",
    "\n",
    "- ttest_1samp:\n",
    "    - Used to compare a sample mean to a population mean.\n",
    "    - Example: Checking if a class's average test score differs from the national average.\n",
    "\n",
    "**Important Notes**\n",
    "\n",
    "The results depend on assumptions:\n",
    "- Normality of data.\n",
    "- Equal variances (for ttest_ind). Use equal_var=False if variances are unequal.\n",
    "Check the assumptions before interpreting the result to ensure validity.\n",
    "\n",
    "#### **How to ensure the validity of a t-test**\n",
    "You must check the underlying assumptions. Here are the common assumptions and how to test them:\n",
    "\n",
    "##### 1.Normality of the Data: \n",
    "\n",
    "The data in each group should follow a normal distribution.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Visual Inspection: Use histograms or Q-Q plots to assess if the data roughly follows a normal curve.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.hist(sample1, bins=10, alpha=0.7, label=\"Sample 1\")\n",
    "plt.hist(sample2, bins=10, alpha=0.7, label=\"Sample 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "stats.probplot(sample1, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Sample 1 Q-Q Plot\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Shapiro-Wilk Test: A formal test for normality. If the p-value is < 0.05, the data significantly deviates from normality.\n",
    "\n",
    "```python\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(sample1)\n",
    "print(\"Shapiro-Wilk Test - Sample 1: stat =\", stat, \", p-value =\", p)\n",
    "\n",
    "stat, p = shapiro(sample2)\n",
    "print(\"Shapiro-Wilk Test - Sample 2: stat =\", stat, \", p-value =\", p)\n",
    "```\n",
    "\n",
    "Kolmogorov-Smirnov Test: Another test for normality (especially for larger samples).\n",
    "\n",
    "```python\n",
    "from scipy.stats import kstest\n",
    "\n",
    "stat, p = kstest(sample1, \"norm\", args=(sample1.mean(), sample1.std()))\n",
    "print(\"K-S Test - Sample 1: stat =\", stat, \", p-value =\", p)\n",
    "```\n",
    "\n",
    "##### 2.Equal Variances (Homogeneity of Variance):\n",
    "\n",
    "The variance in the two groups is similar (only for independent t-tests).\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Levene’s Test:\n",
    "Tests the null hypothesis that the variances are equal. If the p-value is < 0.05, the variances are significantly different.\n",
    "\n",
    "```python\n",
    "from scipy.stats import levene\n",
    "\n",
    "stat, p = levene(sample1, sample2)\n",
    "print(\"Levene's Test: stat =\", stat, \", p-value =\", p)\n",
    "```\n",
    "\n",
    "F-Test (Ratio of Variances):\n",
    "Compare the variances directly.\n",
    "\n",
    "```python\n",
    "f_stat = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
    "print(\"F-statistic (Variance Ratio):\", f_stat)\n",
    "```\n",
    "If variances are unequal, use the equal_var=False parameter in ttest_ind:\n",
    "\n",
    "```python\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_val = ttest_ind(sample1, sample2, equal_var=False)\n",
    "```\n",
    "\n",
    "##### 3.Independence of Observations:\n",
    "\n",
    "Each observation in a sample is independent of others. This is more about the design of your experiment or data collection process.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Verify that your data collection process ensures no overlap or dependence between groups.\n",
    "\n",
    "For time-series data, check for autocorrelation:\n",
    "\n",
    "```python\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(sample1)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "##### What If Assumptions Are Violated?\n",
    "\n",
    "- Normality:\n",
    "    - Use a non-parametric test like the Mann-Whitney U Test (scipy.stats.mannwhitneyu) for independent samples or the Wilcoxon Signed-Rank Test for paired samples.\n",
    "\n",
    "- Equal Variances:\n",
    "    - Use equal_var=False in ttest_ind (Welch’s t-test).\n",
    "\n",
    "- Independence:\n",
    "    - Consider using statistical models (e.g., mixed-effects models) to handle dependencies explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares Regression\n",
    "\n",
    "Ordinary Least Squares (OLS) regression requires checking key assumptions to ensure valid and reliable results. Below are the main assumptions and how to test them:\n",
    "\n",
    "**1. Linearity**\n",
    "\n",
    "The relationship between independent variables and the \n",
    "dependent variable is linear.\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Plot the residuals vs. fitted values. If there is no clear pattern, linearity is likely satisfied.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fitted_values = model.fittedvalues\n",
    "residuals = model.resid\n",
    "\n",
    "plt.scatter(fitted_values, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Fitted Values')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**2. Independence of Errors**\n",
    "\n",
    "The residuals (errors) are independent.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Use the Durbin-Watson statistic. A value close to 2 indicates no autocorrelation.\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(\"Durbin-Watson Statistic:\", dw_stat)\n",
    "```\n",
    "\n",
    "**3. Normality of Errors**\n",
    "\n",
    "The residuals should be normally distributed.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Use a Q-Q plot. Residuals should fall along the diagonal line.\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Perform a Shapiro-Wilk test:\n",
    "\n",
    "```python\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(residuals)\n",
    "print(\"Shapiro-Wilk Test: stat =\", stat, \", p-value =\", p)\n",
    "```\n",
    "\n",
    "**4. Homoscedasticity (Equal Variance of Errors)**\n",
    "\n",
    "The variance of residuals should be constant.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Plot residuals vs. fitted values.\n",
    "\n",
    "Use the Breusch-Pagan test.\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "_, pval, _, _ = het_breuschpagan(residuals, model.model.exog)\n",
    "print(\"Breusch-Pagan Test p-value:\", pval)\n",
    "```\n",
    "\n",
    "**5. No Multicollinearity (for Multiple Regression)**\n",
    "\n",
    "Independent variables should not be highly correlated.\n",
    "\n",
    "<u>How to Check:</u>\n",
    "\n",
    "Compute Variance Inflation Factor (VIF). A VIF > 5 indicates multicollinearity.\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = model.model.exog\n",
    "vif = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "print(\"VIFs:\", vif)\n",
    "```\n",
    "\n",
    "### **Steps Before Running smf.ols**\n",
    "\n",
    "- Ensure linearity by inspecting scatter plots.\n",
    "- Check for multicollinearity if multiple predictors are used.\n",
    "- Perform exploratory data analysis.\n",
    "- After fitting the model, validate assumptions with residual plots.\n",
    "\n",
    "### **Interpreting Model Output**\n",
    "\n",
    "- R-squared: The proportion of the variance in the dependent variable (temp) that is explained by the independent variable (ozone). Example: While the R-squared value of 0.488 shows that ozone explains about 48.8% of the variance in temp, there might be other variables affecting temp not included in this model.\n",
    "- Adjusted R-squared: Similar to R-squared but adjusts for the number of predictors in the model. It penalizes the addition of irrelevant predictors.\n",
    "- F-statistic: measures the overall significance of the model.\n",
    "- Prob (F-statistic): very close to 0 indicates that the model is statistically significant, meaning that independent variables has a significant effect on predicted variable.\n",
    "Log-Likelihood: A measure of the likelihood of the data under the fitted model.\n",
    "- AIC (Akaike Information Criterion): A metric for model comparison, with lower values indicating a better model.\n",
    "- BIC (Bayesian Information Criterion): Similar to AIC but includes a stronger penalty for adding more parameters to the model.\n",
    "- Number of Observations: The total number of data points used in the analysis.\n",
    "- Df Residuals: Degrees of freedom for residuals (number of observations minus the number of parameters).\n",
    "- Df Model: The number of predictors (independent variables) in the model.\n",
    "- Covariance Type: Nonrobust Indicates that standard errors and covariance calculations are not adjusted for heteroskedasticity or autocorrelation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-on-argentina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
